{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FETCHING DATA FROM YOUTUBE IN YOUTUBE SONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('s3://full-stack-bigdata-datasets/Big_Data/youtube_playlog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1392387533</td>\n",
       "      <td>0</td>\n",
       "      <td>t1l8Z6gLPzo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1392387538</td>\n",
       "      <td>1</td>\n",
       "      <td>t1l8Z6gLPzo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1392387556</td>\n",
       "      <td>2</td>\n",
       "      <td>t1l8Z6gLPzo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1392387561</td>\n",
       "      <td>3</td>\n",
       "      <td>we5gzZq5Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1392387566</td>\n",
       "      <td>4</td>\n",
       "      <td>we5gzZq5Avg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  user         song\n",
       "0  1392387533     0  t1l8Z6gLPzo\n",
       "1  1392387538     1  t1l8Z6gLPzo\n",
       "2  1392387556     2  t1l8Z6gLPzo\n",
       "3  1392387561     3  we5gzZq5Avg\n",
       "4  1392387566     4  we5gzZq5Avg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123651"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning dataframe by removing duplicates from song and create a list of songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_id = df.song.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numbers of songs or video in list :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631348"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimation of required api calls and time in hours for collecting data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to do 12626 API calls to fetch all the data.\n",
      "It would take about 7.0 hours to complete.\n"
     ]
    }
   ],
   "source": [
    "required_api_calls = (631348 // 50)\n",
    "time_in_hours = (required_api_calls * 2)/3600\n",
    "\n",
    "print(f'We need to do {required_api_calls} API calls to fetch all the data.')\n",
    "print(f'It would take about {time_in_hours:.1f} hours to complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collect we will use an asynchrone scrypt to be faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimation extraction's quantity data with the limit set by google (10 000 / days)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can perform 10000 calls a day before reaching the API limit.\n",
      "That means we can fetch extra data for 500000 videos per day.\n"
     ]
    }
   ],
   "source": [
    "max_calls = 10000\n",
    "max_videos_count = max_calls * 50\n",
    "\n",
    "print(f'We can perform {max_calls} calls a day before reaching the API limit.')\n",
    "print(f'That means we can fetch extra data for {max_videos_count} videos per day.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetching Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*we are going to fetch only 500 data for training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_sample = song_id[0:500]\n",
    "songs_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUTUBE_API_KEY = 'xxxxxxxx' \n",
    "\n",
    "import os\n",
    "os.environ['YOUTUBE_API_KEY'] = YOUTUBE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_collection import fetch_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-16 08:53:41 UTC]\tINFO\tRequesting data for 500 videos. Please wait...\t(data_collection)\n",
      "[2020-11-16 08:53:42 UTC]\tDEBUG\tAPI call succeeded.\t(data_collection)\n",
      "[2020-11-16 08:53:42 UTC]\tDEBUG\tAPI call succeeded.\t(data_collection)\n",
      "[2020-11-16 08:53:42 UTC]\tDEBUG\tAPI call succeeded.\t(data_collection)\n",
      "[2020-11-16 08:53:42 UTC]\tDEBUG\tAPI call succeeded.\t(data_collection)\n",
      "[2020-11-16 08:53:42 UTC]\tDEBUG\tAPI call succeeded.\t(data_collection)\n",
      "[2020-11-16 08:53:42 UTC]\tDEBUG\tAPI call succeeded.\t(data_collection)\n",
      "[2020-11-16 08:53:42 UTC]\tDEBUG\tAPI call succeeded.\t(data_collection)\n",
      "[2020-11-16 08:53:42 UTC]\tDEBUG\tAPI call succeeded.\t(data_collection)\n",
      "[2020-11-16 08:53:42 UTC]\tDEBUG\tAPI call succeeded.\t(data_collection)\n",
      "[2020-11-16 08:53:42 UTC]\tDEBUG\tAPI call succeeded.\t(data_collection)\n",
      "[2020-11-16 08:53:42 UTC]\tINFO\tDone! Fetched data from 500 videos in 1.65 sec\t(data_collection)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "task = loop.create_task(fetch_all(songs_sample, dry_run=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "result = task.result()\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dumping result in json files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_result = json.dumps(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Storing Data in S3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "\n",
    "logging.getLogger('botocore').setLevel(logging.INFO)\n",
    "logging.getLogger('boto3').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY_ID = 'xxxxxx'\n",
    "SECRET_ACCESS_KEY = 'xxxxxx'\n",
    "\n",
    "session = boto3.Session(ACCESS_KEY_ID, SECRET_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = session.resource('s3')\n",
    "\n",
    "bucket = s3.create_bucket(Bucket = \"xxxxxxxxxxxx\")\n",
    "\n",
    "put_object = bucket.put_object ( Key = \"songs.json\", Body = json_result) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
